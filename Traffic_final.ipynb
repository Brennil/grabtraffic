{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ilo4vb7hx4qv"
   },
   "outputs": [],
   "source": [
    "# Imports the necessary modules\n",
    "import geohash2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJr8f9zwyFkw"
   },
   "source": [
    "# 1. Input the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vNrM1AmnxvEq",
    "outputId": "7984fe7e-7c8c-4e24-d484-cae2c4fca328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the name of the TRAINING data file: /content/gdrive/My Drive/Grab/Traffic/training.csv\n",
      "Training data successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# Reads the training file\n",
    "while True:\n",
    "    try:\n",
    "        fname = input(\"Please enter the name of the TRAINING data file: \")\n",
    "        traffic_data = pd.read_csv(fname)\n",
    "        print(\"Training data successfully loaded.\")\n",
    "        break\n",
    "    except:\n",
    "        print(\"File does not exist! Please try again!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAn-4ppTzK-p"
   },
   "source": [
    "# 2. Prepare Features in Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_wYOqE9zFEb"
   },
   "outputs": [],
   "source": [
    "def features(dataset):\n",
    "    '''\n",
    "    Takes a data set and pre-processes it to generate the features\n",
    "    :Inputs: \n",
    "    dataset: a dataframe with each row describing a data point\n",
    "    :Returns:\n",
    "    feature_set: a dataframe with the features for training the model\n",
    "    dataset.demand: a dataseries with the targets of the model\n",
    "    '''\n",
    "    \n",
    "    # Convert time into consecutive time periods, with 0 denoting midnight, and 95 denoting 23:45\n",
    "    time = []\n",
    "    for row in dataset.timestamp:\n",
    "        h,m = row.split(\":\")\n",
    "        time.append(4 * int(h) + int(m) / 15)\n",
    "        \n",
    "    time_period = pd.Series(time)\n",
    "    \n",
    "    # Convert the day given in the data into a day of the week, from 0 to 6\n",
    "    # This based on the assumption that demand will be similar for the same day of the week\n",
    "    days_in_seven = []\n",
    "    for row in dataset.day:\n",
    "        days_in_seven.append(row%7)\n",
    "    \n",
    "    days_in_seven = pd.Series(days_in_seven)\n",
    "    \n",
    "    # Split the geohash into latitude and longitude, then combine them into \"squares\" of area on the map\n",
    "    # Instead of treating latitude and longitude as independent of each other, assigning a value for each \n",
    "    # latitude-longitude pair and treating them as a single \"area\" feature is more meaningful.\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    for row in dataset.geohash6:\n",
    "        lat, long = geohash2.decode(row)\n",
    "        latitudes.append(float(lat))\n",
    "        longitudes.append(float(long))\n",
    "    \n",
    "    areas = []\n",
    "    latitude_min = min(latitudes)\n",
    "    longitude_min = min(longitudes)\n",
    "    i_range = 100 * (max(latitudes) - min(latitudes)) + 1\n",
    "    for i in range(len(latitudes)):\n",
    "        area = 100 * i_range * (latitudes[i] - latitude_min) + 100 * (longitudes[i] - longitude_min)\n",
    "        areas.append(area)\n",
    "    \n",
    "    areas = pd.Series(areas)\n",
    "    \n",
    "    feature_set = pd.DataFrame({'area': areas,\n",
    "                                'day in seven': days_in_seven,\n",
    "                                'time period': time_period})\n",
    "    \n",
    "    return feature_set, dataset.demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bRjhbD80kvj"
   },
   "outputs": [],
   "source": [
    "# Generates the features (X) and targets (y) based on the training data\n",
    "X, y = features(traffic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f94qE5XG2bK_"
   },
   "source": [
    "# 3. Fit the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lqsungzk2a4D"
   },
   "outputs": [],
   "source": [
    "def fitting(X, y, validation=True,test_size=0.33, random_state=42):\n",
    "    '''\n",
    "    Takes a data set and fits it using a Random Forest model\n",
    "    :Inputs:\n",
    "    X, y : the data set to fit using the model. X represents the features and y represents the targets\n",
    "    validation : if True, will split the data set into a training and validation set for evaluating the model\n",
    "    test_size : if validation is True, will set aside this fraction of the data set for validation\n",
    "    random_state : seed for the random state of the model and the training-validation split\n",
    "    :Returns:\n",
    "    model: a trained Random Forest Regressor model, trained with the features (X) and targets (y) input\n",
    "    '''\n",
    "    \n",
    "    if validation:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = test_size, random_state=random_state)\n",
    "        model = RandomForestRegressor(random_state=random_state, n_estimators=100, min_samples_leaf=0.001, oob_score = True, bootstrap = True)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "        print('The score on the validation set is {}.'.format(score))\n",
    "    else:\n",
    "        model = RandomForestRegressor(random_state=random_state, n_estimators=100, min_samples_leaf=0.001, oob_score = True, bootstrap = True)\n",
    "        model.fit(X, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ahJ6TSSa2R6d",
    "outputId": "4432ed04-38a6-4d24-ce27-025f712f9baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the validation set is 0.13530557000274804.\n"
     ]
    }
   ],
   "source": [
    "# Trains the model with the training data (X) and targets (y)\n",
    "traffic_model = fitting(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vAzT2U460me"
   },
   "source": [
    "# 4. Input the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NfokKyPU60T0",
    "outputId": "a3e99dc5-a2a2-41f5-8aca-172aad267f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the name of the TEST data file: /content/gdrive/My Drive/Grab/Traffic/training.csv\n",
      "Test data successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# Reads the test file\n",
    "while True:\n",
    "    try:\n",
    "        fname = input(\"Please enter the name of the TEST data file: \")\n",
    "        traffic_data = pd.read_csv(fname)\n",
    "        print(\"Test data successfully loaded.\")\n",
    "        break\n",
    "    except:\n",
    "        print(\"File does not exist! Please try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rSLG-mL6zWvP",
    "outputId": "107f33a6-600d-46bf-d06c-0971ef4c1712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is 0.13543015396325933\n"
     ]
    }
   ],
   "source": [
    "# Generates features (X_test) and targets (y_test) for test data\n",
    "X_test, y_test = features(traffic_data)\n",
    "\n",
    "# Uses the trained model to predict the output based on the test features, \n",
    "# then generates a score based on the root-mean-squared-error of the difference \n",
    "# between the actual targets and the predicted targets\n",
    "y_test_pred = traffic_model.predict(X_test)\n",
    "score = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"The score on the test set is {}\".format(score))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Traffic_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
